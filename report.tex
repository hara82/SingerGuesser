\documentclass[a4paper,11pt]{article}


% 数式
\usepackage{amsmath,amsfonts}
\usepackage{bm}
\usepackage{here}
% 画像
\usepackage[dvipdfmx]{graphicx}
% hyperlink
\usepackage{hyperref}


\begin{document}

\title{Text-as-Data Learning Coursework}
\author{2822260H Ryosuke Hara}
\date{\today}
\maketitle

\section{Q1- Dataset}
\subsection{a) Overview of data}% 数式
The dataset used in this experiment is the lyrics of songs of famous singers.
Singers are chosen from a ranking in a website, \href{https://www.thefamouspeople.com/21st-century-singers.php}{"The greatest 21st century singers"}, to minimise the arbitrary choice of the author.

Lyrics were obtained by using lyricsgenius, a python API of Genius.com.
Since lyrics were fetched online, it includes some HTML tokens and some meta data about translation inside the lyrics.
The meta data about translation are supposed to be removed by preprocessing.
Also, there are some faulty data where texts are not lyrics or lyrics are too short because it is cut in the middle of a song.
Too short lyrics where the total length is under 300 characters are removed automatically, and too long data are removed manually by inspecting the text.
To minimise the duplication of a same song, songs including certain keywords,such as "remix", "vergion", are ignored.


The main objective is to infer the singer from lyrics of a song.
I chose this dataset because I wanted to examine whether lyrics reflect singers' characteristics like the musical elements do.

Automatic classification has several applications.
It can be used for helping singers maintain the same trend among an album,
suggesting new singers for music listeners in recommendation system of music service like Spotify, 
detecting improper mimicking of the lyrics among singers. 

\subsection{b) Overview of input texts and labels}
summary of the labels and input text to be used \\

There are ten labels and each label is a name of a singer, which is to be predicted.
Singers are: "Ariana Grande", "Michael Jackson","Taylor Swift","XXXTentacion","Eminem", "Lady Gaga","Selena Gomez","Beyonce Knowles","Dua Lipa",'Jennifer Lopez.'
This dataset is not multi-label and does not consider a song from more than 2 singers.
Preprocessing of labels were unnecessary because texts were collected from a label.


Input texts are a title of a song and its lyrics concatenated with a new line character.
There are 1784 documents in total, 
and the length of input texts varies from 305 characters to 13102 characters.
The distribution of the length of text is shown in Figure 1.
\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=70mm]{figures/text_length.png}
  \caption{distribution of text length}
  \end{center}
\end{figure}



\subsection{c) spliting data}
The dataset is not split into a training, validation, and test set at first, 
so it was split into 60/20/20\% using "train\_test\_split" of scikit-learn.
The label counts for each split dataset is shown in Figure 2.
All labels have 100 to 200 documents in total and are not too imbalanced.



\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=140mm]{figures/text_labels2.png}
  \caption{label counts for each split}
  \end{center}
\end{figure}

% \begin{table}[htbp]
%   \centering
%   \begin{tabular}{l|c|r}
%     1 & 2 & 3 \\ \hline\hline
%     sin & cos & tan \\
%     apple & pine & banana \\ \hline
%   \end{tabular}
%   \caption{fugafuga}
%   \label{tb:fugafuga}
% \end{table}


% \subsection{steps to build the dataset}

\section{Q2- Clustering}
\subsection{Vectorizing texts}
Firstly, texts were converted into vectors to conduct clustering.
TfidfVectorizer from scikit-learn, along with 'en\_core\_web\_sm' from spacy were used.

Before converted to vectors, texts were firstly tokenized, and also stop words were removed.
Stop words were defined by the spacy models and manually added words, which are mainly interjections as "oh", "ah."
Such manually added words were chosen so that they do not show in the top 5 tokens of each cluster.
Stop words were removed because they do not convey much meaning and prevent understanding the characteristics of each cluster.

As for input, a title and lyrics of a song combined was used for an input because a title tend to be too short.


\subsection{a) Documents assigned to each cluster}
K-mean clustering was conducted with k=5.
The first 200 characters of 3 documents in each cluster are shown below.
% texts

Besides, the top 5 tokens with highest magnitude in each centroid is listed below.
% tokens




\subsection{b) Examining clusters}
\subsection{c) Confusion matrix}
\subsection{d) Examining the confusion matrix}



\section{Q3- Comparing Classifiers}
\subsection{a) 5 baseline classifiers}
\subsection{b) My chosen classifier}

\section{Q4- Parameter Tuning}
\subsection{Classifier}
\subsection{Vectorizer}
\subsection{My own parameter}


\section{Context vectors using BERT}
\subsection{feature extraction and logistic regression}
\subsection{end-to-end trained classifier}
\subsection{Selecting hyperparameters and models}
\subsection{Examining models and parameters}


\section{Q6- Conclusions and Future Work}
















\end{document}