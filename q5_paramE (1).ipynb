{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"46b2c09a318b4ff183d17d87f996652f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bedfda7297d74264b79c338e9965bd1d","IPY_MODEL_5c523373853c45bcafaa50b7e1afe708","IPY_MODEL_b792fdfecf0848ed8d62b1c72c49b5e0"],"layout":"IPY_MODEL_75fbdd0a653143c1af45f59782d31c80"}},"bedfda7297d74264b79c338e9965bd1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d39f6576c5a424f9ed48dc999ebd410","placeholder":"​","style":"IPY_MODEL_1255cf15ba484c849d238c8d9d90d8a2","value":"Downloading (…)lve/main/config.json: 100%"}},"5c523373853c45bcafaa50b7e1afe708":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0a3a8f1035643c99db08711090bd12b","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b0cad92834e47ae81571ca814b58a0d","value":481}},"b792fdfecf0848ed8d62b1c72c49b5e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0119d5b37a0345919c506ebfdc32a6b9","placeholder":"​","style":"IPY_MODEL_26c9547d5b7041b8a67237f9ead575eb","value":" 481/481 [00:00&lt;00:00, 8.40kB/s]"}},"75fbdd0a653143c1af45f59782d31c80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d39f6576c5a424f9ed48dc999ebd410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1255cf15ba484c849d238c8d9d90d8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a3a8f1035643c99db08711090bd12b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b0cad92834e47ae81571ca814b58a0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0119d5b37a0345919c506ebfdc32a6b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c9547d5b7041b8a67237f9ead575eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b90a9c82b41742a98795fa7fb0ecf463":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f87d9f95fac947339d6488cea8a0e947","IPY_MODEL_c9ac4a40e50d45f1badc10700c1de99c","IPY_MODEL_32adffb17963461f9862f8d9b63367a3"],"layout":"IPY_MODEL_f2e2818fcbc142489ea03f70a4bdd568"}},"f87d9f95fac947339d6488cea8a0e947":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c61a69df4fad4bbd9486aa4854a65ead","placeholder":"​","style":"IPY_MODEL_0bc1e318139743e6bda157717e88e781","value":"Downloading pytorch_model.bin: 100%"}},"c9ac4a40e50d45f1badc10700c1de99c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dfb5ebcef6f4c47be7cbfe1643aa996","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d51e21ae7cc4604a68b5611eb5738f7","value":501200538}},"32adffb17963461f9862f8d9b63367a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9973d34c4dd5468e802036a30d8324b2","placeholder":"​","style":"IPY_MODEL_a91032d570954f498b043adf5b0331a7","value":" 501M/501M [00:04&lt;00:00, 114MB/s]"}},"f2e2818fcbc142489ea03f70a4bdd568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61a69df4fad4bbd9486aa4854a65ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bc1e318139743e6bda157717e88e781":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dfb5ebcef6f4c47be7cbfe1643aa996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d51e21ae7cc4604a68b5611eb5738f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9973d34c4dd5468e802036a30d8324b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a91032d570954f498b043adf5b0331a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c65f9c6c8924130ae371bf0c48907b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22fc93f4b31c47f1b0753e3f50a14eff","IPY_MODEL_71b3f739270e47dfb22425c6a1df9d9d","IPY_MODEL_a5d7a58c11b7406db7c1be7895b818ac"],"layout":"IPY_MODEL_90f617c6433e43b8ba6edc472bc3c5e7"}},"22fc93f4b31c47f1b0753e3f50a14eff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1855c695b9478c9fd1ca9495864f3e","placeholder":"​","style":"IPY_MODEL_12b635fef1a04a81873ed19f9b5a3931","value":"Downloading (…)olve/main/vocab.json: 100%"}},"71b3f739270e47dfb22425c6a1df9d9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c92d3f2ab30d49d1a6572597309fbdae","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afb0bb76788c4b2899b89081f35549a7","value":898823}},"a5d7a58c11b7406db7c1be7895b818ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fe5cd789e454459a05cd1454100dd44","placeholder":"​","style":"IPY_MODEL_dc6867543c244556a3e692df330be50e","value":" 899k/899k [00:00&lt;00:00, 4.86MB/s]"}},"90f617c6433e43b8ba6edc472bc3c5e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1855c695b9478c9fd1ca9495864f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b635fef1a04a81873ed19f9b5a3931":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c92d3f2ab30d49d1a6572597309fbdae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afb0bb76788c4b2899b89081f35549a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fe5cd789e454459a05cd1454100dd44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc6867543c244556a3e692df330be50e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"befb0c451e754fbd96e40de6cf2fb690":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a37eb055a7eb4d88b22a9fc04a0cf9ca","IPY_MODEL_228c0c8b83ee4263b8c6d94720ca9b01","IPY_MODEL_dc37bf95a31d4c0099c3b5735edbd217"],"layout":"IPY_MODEL_3c6f1c4ae8e143d7916eba80326bf8d1"}},"a37eb055a7eb4d88b22a9fc04a0cf9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cad431055d1549feb75ce71bcbdb9d8a","placeholder":"​","style":"IPY_MODEL_2825fa81f0ca4a15b459f45e68cd50cc","value":"Downloading (…)olve/main/merges.txt: 100%"}},"228c0c8b83ee4263b8c6d94720ca9b01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93ffcea8a2d24db0a7ccc22135c6fade","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_906d02717f2a44bab66a06b1d61b8386","value":456318}},"dc37bf95a31d4c0099c3b5735edbd217":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aea0cc123002491691f75a2728a69993","placeholder":"​","style":"IPY_MODEL_b671053eb88c4569a4a4e2e078fcbf98","value":" 456k/456k [00:00&lt;00:00, 2.20MB/s]"}},"3c6f1c4ae8e143d7916eba80326bf8d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad431055d1549feb75ce71bcbdb9d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2825fa81f0ca4a15b459f45e68cd50cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93ffcea8a2d24db0a7ccc22135c6fade":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906d02717f2a44bab66a06b1d61b8386":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aea0cc123002491691f75a2728a69993":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b671053eb88c4569a4a4e2e078fcbf98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"523a5179315743d0b069340d9cffe51b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_281d8d91b83c47e5820801f17f660d45","IPY_MODEL_37f79fb6d3944566ac3f35391a31e9c2","IPY_MODEL_195702ed94304d78b63d694ad8ed64dd"],"layout":"IPY_MODEL_287cbc922b3b4d708e0767c25bbd6f8e"}},"281d8d91b83c47e5820801f17f660d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b0ca740fb4141e9b0be02144a26e0e4","placeholder":"​","style":"IPY_MODEL_7d3577592ae54759bbaacf518b17c42e","value":"Downloading (…)/main/tokenizer.json: 100%"}},"37f79fb6d3944566ac3f35391a31e9c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_679f1217117842239d66af82bae69e28","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67e8ed18853b4849ac87edca0b38fcd9","value":1355863}},"195702ed94304d78b63d694ad8ed64dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3474f787473b4af7a009c5957e548f13","placeholder":"​","style":"IPY_MODEL_1d9b8286510c48ca8ecd74c97959d89f","value":" 1.36M/1.36M [00:00&lt;00:00, 6.46MB/s]"}},"287cbc922b3b4d708e0767c25bbd6f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b0ca740fb4141e9b0be02144a26e0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d3577592ae54759bbaacf518b17c42e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"679f1217117842239d66af82bae69e28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67e8ed18853b4849ac87edca0b38fcd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3474f787473b4af7a009c5957e548f13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d9b8286510c48ca8ecd74c97959d89f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ras_hAG7itA3","executionInfo":{"status":"ok","timestamp":1678570687444,"user_tz":0,"elapsed":23534,"user":{"displayName":"Ryosuke HARA","userId":"14758738608613309303"}},"outputId":"8e95bbce-e7a5-4544-aeea-c66e5ef61173"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pickle\n","file_path = './splitData.pickle'\n","with open(file_path, 'rb') as f:\n","    texts_train = pickle.load(f)\n","    texts_val = pickle.load(f)\n","    texts_test = pickle.load(f)\n","    labels_train = pickle.load(f)\n","    labels_val = pickle.load(f)\n","    labels_test = pickle.load(f)\n","\n","all_texts  = texts_train  + texts_val  + texts_test\n","all_labels = labels_train + labels_val + labels_test\n","# check the ratio of each dataset\n","total = len(texts_train) + len(texts_val) + len(texts_test)\n","len(texts_train)/total, len(texts_val)/total, len(texts_test)/total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6UA6UoDm3Sd","executionInfo":{"status":"ok","timestamp":1678617555569,"user_tz":0,"elapsed":14,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"1b3c4360-13ef-4ce4-fac7-59b1a9239747"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.5997757847533632, 0.20011210762331838, 0.20011210762331838)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYUJ1Qdcm7Cm","executionInfo":{"status":"ok","timestamp":1678617535183,"user_tz":0,"elapsed":29620,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"b5daca70-f801-4891-9869-b3eb78f7dcfd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.3.5)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting charset-normalizer<4.0,>=2.0\n","  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, charset-normalizer, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.1 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import pipeline\n","pipe = pipeline('feature-extraction',model='roberta-base',truncation=True)# Truncation is needed to handle longer documents over 512 tokens\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251,"referenced_widgets":["46b2c09a318b4ff183d17d87f996652f","bedfda7297d74264b79c338e9965bd1d","5c523373853c45bcafaa50b7e1afe708","b792fdfecf0848ed8d62b1c72c49b5e0","75fbdd0a653143c1af45f59782d31c80","8d39f6576c5a424f9ed48dc999ebd410","1255cf15ba484c849d238c8d9d90d8a2","f0a3a8f1035643c99db08711090bd12b","9b0cad92834e47ae81571ca814b58a0d","0119d5b37a0345919c506ebfdc32a6b9","26c9547d5b7041b8a67237f9ead575eb","b90a9c82b41742a98795fa7fb0ecf463","f87d9f95fac947339d6488cea8a0e947","c9ac4a40e50d45f1badc10700c1de99c","32adffb17963461f9862f8d9b63367a3","f2e2818fcbc142489ea03f70a4bdd568","c61a69df4fad4bbd9486aa4854a65ead","0bc1e318139743e6bda157717e88e781","0dfb5ebcef6f4c47be7cbfe1643aa996","9d51e21ae7cc4604a68b5611eb5738f7","9973d34c4dd5468e802036a30d8324b2","a91032d570954f498b043adf5b0331a7","4c65f9c6c8924130ae371bf0c48907b6","22fc93f4b31c47f1b0753e3f50a14eff","71b3f739270e47dfb22425c6a1df9d9d","a5d7a58c11b7406db7c1be7895b818ac","90f617c6433e43b8ba6edc472bc3c5e7","4e1855c695b9478c9fd1ca9495864f3e","12b635fef1a04a81873ed19f9b5a3931","c92d3f2ab30d49d1a6572597309fbdae","afb0bb76788c4b2899b89081f35549a7","9fe5cd789e454459a05cd1454100dd44","dc6867543c244556a3e692df330be50e","befb0c451e754fbd96e40de6cf2fb690","a37eb055a7eb4d88b22a9fc04a0cf9ca","228c0c8b83ee4263b8c6d94720ca9b01","dc37bf95a31d4c0099c3b5735edbd217","3c6f1c4ae8e143d7916eba80326bf8d1","cad431055d1549feb75ce71bcbdb9d8a","2825fa81f0ca4a15b459f45e68cd50cc","93ffcea8a2d24db0a7ccc22135c6fade","906d02717f2a44bab66a06b1d61b8386","aea0cc123002491691f75a2728a69993","b671053eb88c4569a4a4e2e078fcbf98","523a5179315743d0b069340d9cffe51b","281d8d91b83c47e5820801f17f660d45","37f79fb6d3944566ac3f35391a31e9c2","195702ed94304d78b63d694ad8ed64dd","287cbc922b3b4d708e0767c25bbd6f8e","2b0ca740fb4141e9b0be02144a26e0e4","7d3577592ae54759bbaacf518b17c42e","679f1217117842239d66af82bae69e28","67e8ed18853b4849ac87edca0b38fcd9","3474f787473b4af7a009c5957e548f13","1d9b8286510c48ca8ecd74c97959d89f"]},"id":"yQZjFCGCm9_I","executionInfo":{"status":"ok","timestamp":1678617555567,"user_tz":0,"elapsed":20392,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"5084d1be-9794-46d2-e0f7-59a14e6db633"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b2c09a318b4ff183d17d87f996652f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90a9c82b41742a98795fa7fb0ecf463"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c65f9c6c8924130ae371bf0c48907b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"befb0c451e754fbd96e40de6cf2fb690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"523a5179315743d0b069340d9cffe51b"}},"metadata":{}}]},{"cell_type":"code","source":["# Show classifier performance\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","def showPerformance(labels_true, labels_predicted):\n","    print(f'accuracy ={accuracy_score(labels_true, labels_predicted):.3f}')\n","    print(f'precision={precision_score(labels_true, labels_predicted, average=\"macro\"):.3f}')\n","    print(f'recall   ={recall_score(labels_true, labels_predicted, average=\"macro\"):.3f}') \n","    print(f'f1       ={f1_score(labels_true, labels_predicted, average=\"macro\"):.3f}')\n","    return ;"],"metadata":{"id":"R3qEqBqfnEdn","executionInfo":{"status":"ok","timestamp":1678617555568,"user_tz":0,"elapsed":16,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# C"],"metadata":{"id":"JKPb8it-nU34"}},{"cell_type":"markdown","source":["### Creating a Dataset"],"metadata":{"id":"5HsrKrKHnYN5"}},{"cell_type":"code","source":["# correspond labels(songer names) with integers\n","label2id = {label: i for i, label in enumerate(set(labels_train))}\n","id2label = {id:label for label,id in label2id.items()}\n","labels_train_int = [label2id[l] for l in labels_train]\n","labels_val_int = [label2id[l] for l in labels_val]"],"metadata":{"id":"-AigyJ23nGXC","executionInfo":{"status":"ok","timestamp":1678617555569,"user_tz":0,"elapsed":11,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from datasets import Dataset\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","\n","def createDataset(texts, labels_int):\n","    encoded_texts = []\n","    for t in texts:\n","        encoded_texts.append(tokenizer.encode(t,truncation=True))#,max_length=128))### max_length need to be changed\n","    \n","    dataset = Dataset.from_dict({\n","        \"input_ids\":encoded_texts,\n","        \"labels\": labels_int\n","    })\n","    return dataset\n","\n","train_dataset = createDataset(texts_train, labels_train_int)\n","validation_dataset = createDataset(texts_val, labels_val_int)"],"metadata":{"id":"50nu-yz4nbmE","executionInfo":{"status":"ok","timestamp":1678617562298,"user_tz":0,"elapsed":6739,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import set_seed, AutoModelForSequenceClassification\n","\n","set_seed(42)\n","\n","model = AutoModelForSequenceClassification.from_pretrained('roberta-base',id2label=id2label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOpqL-ynngnJ","executionInfo":{"status":"ok","timestamp":1678617565980,"user_tz":0,"elapsed":3685,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"bb409696-9ef3-4fef-c5eb-8d6afa49c59b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# 3 sets of parameters\n","# Batch size cannot be over 16 due to memory issue.\n","\n","# make model sensitive to each data by decreasing batch_size and increasing learning_rate\n","param_a = {\"learning_rate\":1e-3,\n","           \"epochs\": 10,\n","           \"batch_size\":4}\n","\n","# make model less sensitive to each data by increasing batch_size and decreasing learning_rate. increase epochs instead to help converge.\n","param_b = {\"learning_rate\":1e-5,\n","           \"epochs\":50 ,\n","           \"batch_size\":16}\n","\n","# middle of A and B\n","param_c = {\"learning_rate\":1e-4,\n","           \"epochs\": 25,\n","           \"batch_size\":8}\n","\n","# param_b gained the best result (f1 = 0.586), so minor change from param_b\n","param_d = {\"learning_rate\":1e-5,\n","           \"epochs\":50 ,\n","           \"batch_size\":8}\n","\n","param_e = {\"learning_rate\":1e-5,\n","           \"epochs\":75 ,\n","           \"batch_size\":16}       "],"metadata":{"id":"EL9ogqWznkqA","executionInfo":{"status":"ok","timestamp":1678617600220,"user_tz":0,"elapsed":181,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer,DataCollatorWithPadding\n","\n","def createTrainer(p,name):\n","  training_args = TrainingArguments(\n","      output_dir                 = f\"model_{name}\", # HuggingFace wants a name for your model\n","      evaluation_strategy        = \"epoch\", # How often we want to evaluate the model\n","      learning_rate              = p[\"learning_rate\"], # Hyperparameter\n","      per_device_train_batch_size= p[\"batch_size\"], # Hyperparameter\n","      per_device_eval_batch_size = p[\"batch_size\"], # Hyperparameter\n","      num_train_epochs           = p[\"epochs\"] # Hyperparameter\n","      # weight_decay=weight_decay, # Hyperparameter\n","  )\n","  data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","    # training\n","  trainer = Trainer(\n","      model=model, # The model you want to train\n","      args=training_args, # The various training arguments set up above\n","      train_dataset=train_dataset, # The data to use to update the weights\n","      eval_dataset=validation_dataset, # The data to use \n","      tokenizer=tokenizer, # The tokenizer used on the data\n","      data_collator=data_collator, # A data collator that does clever things moving data around\n","      )\n","  return trainer\n"],"metadata":{"id":"teJPSW8Fny55","executionInfo":{"status":"ok","timestamp":1678617565983,"user_tz":0,"elapsed":21,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Show classifier performance\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","def showPerformance(labels_true, labels_predicted):\n","    print(f'accuracy ={accuracy_score(labels_true, labels_predicted):.3f}')\n","    print(f'precision={precision_score(labels_true, labels_predicted, average=\"macro\"):.3f}')\n","    print(f'recall   ={recall_score(labels_true, labels_predicted, average=\"macro\"):.3f}') \n","    print(f'f1       ={f1_score(labels_true, labels_predicted, average=\"macro\"):.3f}')\n","    return ;\n","\n","def evalModel(trainer,name):\n","    # measuring metrics with validation set\n","  predictions, label_ids, metrics = trainer.predict(validation_dataset)\n","  labels_predicted = predictions.argmax(axis=1)\n","  print(f'----------model{name}---------')\n","  showPerformance(label_ids, labels_predicted)\n","  return ;\n"],"metadata":{"id":"4YiWJvOvpP-i","executionInfo":{"status":"ok","timestamp":1678617565985,"user_tz":0,"elapsed":21,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["trainer = createTrainer(param_e,\"e\")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hjSo-W3GoLKl","outputId":"48b83715-d2fa-4105-9796-c4254a4e39ed","executionInfo":{"status":"ok","timestamp":1678627062557,"user_tz":0,"elapsed":9458007,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 1070\n","  Num Epochs = 75\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5025\n","  Number of trainable parameters = 124653322\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5025' max='5025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5025/5025 2:37:36, Epoch 75/75]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.113155</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>1.731240</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>1.522281</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>1.476593</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>1.389152</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>1.325397</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>1.559131</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.283300</td>\n","      <td>1.469840</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.283300</td>\n","      <td>1.464493</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.283300</td>\n","      <td>1.511230</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.283300</td>\n","      <td>1.560122</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.283300</td>\n","      <td>1.519134</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.283300</td>\n","      <td>1.775614</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.283300</td>\n","      <td>1.886622</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.209400</td>\n","      <td>1.862338</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.209400</td>\n","      <td>2.171072</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.209400</td>\n","      <td>2.158979</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.209400</td>\n","      <td>2.323458</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.209400</td>\n","      <td>2.354089</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.209400</td>\n","      <td>2.399407</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.209400</td>\n","      <td>2.503703</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.209400</td>\n","      <td>2.444718</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.009900</td>\n","      <td>2.548820</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.009900</td>\n","      <td>2.610249</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.009900</td>\n","      <td>2.607961</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.009900</td>\n","      <td>2.667608</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.009900</td>\n","      <td>2.723281</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.009900</td>\n","      <td>2.693299</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.009900</td>\n","      <td>2.726247</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.001600</td>\n","      <td>2.749032</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.001600</td>\n","      <td>2.800852</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.001600</td>\n","      <td>2.829165</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.001600</td>\n","      <td>2.836139</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.001600</td>\n","      <td>2.864564</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.001600</td>\n","      <td>2.836166</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.001600</td>\n","      <td>2.879911</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.001600</td>\n","      <td>2.883029</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.001000</td>\n","      <td>2.916051</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.001000</td>\n","      <td>2.933205</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.001000</td>\n","      <td>2.926181</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.001000</td>\n","      <td>2.953316</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.001000</td>\n","      <td>2.999029</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.001000</td>\n","      <td>2.974579</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.001000</td>\n","      <td>3.011700</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000700</td>\n","      <td>3.030541</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000700</td>\n","      <td>3.040987</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000700</td>\n","      <td>3.033971</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000700</td>\n","      <td>3.061817</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000700</td>\n","      <td>3.035468</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000700</td>\n","      <td>3.069485</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000700</td>\n","      <td>3.092956</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000700</td>\n","      <td>3.097780</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000500</td>\n","      <td>3.136265</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000500</td>\n","      <td>3.133348</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000500</td>\n","      <td>3.093146</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000500</td>\n","      <td>3.136572</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000500</td>\n","      <td>3.136434</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000500</td>\n","      <td>3.146424</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000500</td>\n","      <td>3.142339</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000400</td>\n","      <td>3.153169</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000400</td>\n","      <td>3.159677</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000400</td>\n","      <td>3.184009</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000400</td>\n","      <td>3.146173</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000400</td>\n","      <td>3.191713</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000400</td>\n","      <td>3.185565</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000400</td>\n","      <td>3.202612</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000400</td>\n","      <td>3.210521</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000400</td>\n","      <td>3.212510</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000400</td>\n","      <td>3.203034</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000400</td>\n","      <td>3.206720</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000400</td>\n","      <td>3.239738</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000400</td>\n","      <td>3.221554</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000400</td>\n","      <td>3.214559</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000400</td>\n","      <td>3.214069</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000300</td>\n","      <td>3.211679</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-500\n","Configuration saved in model_e/checkpoint-500/config.json\n","Model weights saved in model_e/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-1000\n","Configuration saved in model_e/checkpoint-1000/config.json\n","Model weights saved in model_e/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-1500\n","Configuration saved in model_e/checkpoint-1500/config.json\n","Model weights saved in model_e/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-1500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-2000\n","Configuration saved in model_e/checkpoint-2000/config.json\n","Model weights saved in model_e/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-2000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-2500\n","Configuration saved in model_e/checkpoint-2500/config.json\n","Model weights saved in model_e/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-2500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-3000\n","Configuration saved in model_e/checkpoint-3000/config.json\n","Model weights saved in model_e/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-3000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-3500\n","Configuration saved in model_e/checkpoint-3500/config.json\n","Model weights saved in model_e/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-3500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-4000\n","Configuration saved in model_e/checkpoint-4000/config.json\n","Model weights saved in model_e/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-4000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-4500\n","Configuration saved in model_e/checkpoint-4500/config.json\n","Model weights saved in model_e/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-4500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","Saving model checkpoint to model_e/checkpoint-5000\n","Configuration saved in model_e/checkpoint-5000/config.json\n","Model weights saved in model_e/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in model_e/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in model_e/checkpoint-5000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 357\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=5025, training_loss=0.15000837858618046, metrics={'train_runtime': 9457.6835, 'train_samples_per_second': 8.485, 'train_steps_per_second': 0.531, 'total_flos': 2.1116178832896e+16, 'train_loss': 0.15000837858618046, 'epoch': 75.0})"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["evalModel(trainer,\"e\")"],"metadata":{"id":"sBdA9z1lovnP","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1678627074718,"user_tz":0,"elapsed":12186,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"db9b52f7-ac23-4cb9-a5d7-8916d24ca2cb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 357\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------modele---------\n","accuracy =0.583\n","precision=0.611\n","recall   =0.590\n","f1       =0.581\n"]}]},{"cell_type":"code","source":["trainer.save_model(\"./paramE\")\n"],"metadata":{"id":"26rInJs7o-9q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678627110284,"user_tz":0,"elapsed":1790,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"4a9fba4b-612f-4896-87b4-a1406ad556e4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./paramE\n","Configuration saved in ./paramE/config.json\n","Model weights saved in ./paramE/pytorch_model.bin\n","tokenizer config file saved in ./paramE/tokenizer_config.json\n","Special tokens file saved in ./paramE/special_tokens_map.json\n"]}]},{"cell_type":"code","source":["!zip -r /content/modelE.zip /content/model_e\n","!zip -r /content/paramE.zip /paramE"],"metadata":{"id":"Yy-q_J6-OVlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/modelE.zip\")\n","files.download(\"/content/paramE.zip\")"],"metadata":{"id":"rrP_d7XLOaI3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## creating test dataset"],"metadata":{"id":"iHHQ78hdLjg3"}},{"cell_type":"code","source":["labels_test_int = [label2id[l] for l in labels_test]\n","test_dataset = createDataset(texts_test, labels_test_int)"],"metadata":{"id":"alsmxDZuLjKa","executionInfo":{"status":"ok","timestamp":1678627075378,"user_tz":0,"elapsed":673,"user":{"displayName":"けろりん","userId":"09772905218308909693"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["t_predictions, t_label_ids, t_metrics = trainer.predict(test_dataset)\n","t_labels_predicted = t_predictions.argmax(axis=1)\n","print(f'----------test---------')\n","showPerformance(t_label_ids, t_labels_predicted)\n","\n","with open(\"test_resultsE.pickle\",\"wb\") as f:\n","  pickle.dump(t_labels_predicted, f)\n","  pickle.dump(t_label_ids, f)\n","from google.colab import files\n","\n","files.download(\"test_resultsE.pickle\")"],"metadata":{"id":"JgDR3DonMfzT","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1678627168754,"user_tz":0,"elapsed":14660,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"a27330bd-189d-4e9e-f4bd-e15b9e7d62b0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 357\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------test---------\n","accuracy =0.597\n","precision=0.617\n","recall   =0.592\n","f1       =0.591\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_87bf10f4-de64-4a1d-8a7a-22f907a74ffa\", \"test_resultsE.pickle\", 6014)"]},"metadata":{}}]},{"cell_type":"code","source":["print(t_labels_predicted[:10])\n","print(t_label_ids[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8B6r3HfhaPC8","executionInfo":{"status":"ok","timestamp":1678627218788,"user_tz":0,"elapsed":4,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"51b82b53-2125-448b-de73-267678250053"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 5 8 2 2 8 5 6 8 6]\n","[0 2 0 1 2 8 5 9 5 6]\n"]}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXRHNK93_Azn","executionInfo":{"status":"ok","timestamp":1678627380054,"user_tz":0,"elapsed":1652,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"917e0a4b-4bc4-4602-95fd-c5a03be23641"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]}]},{"cell_type":"code","source":["a = test_dataset[54][\"input_ids\"][:50]\n","print(tokenizer.decode(a))\n","print(id2label[test_dataset[54][\"labels\"]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dug3c65u-qE0","executionInfo":{"status":"ok","timestamp":1678627502841,"user_tz":0,"elapsed":279,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"cca09122-dee7-4231-9953-758a54193465"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>Diamonds Are Invincible (Mark Ronson x Michael Jackson)\n","Diamonds Are Invincible (Mark Ronson x Michael Jackson) Lyrics\n","Keep on with the force don't stop\n","Don't stop 'til you get enough\n","Keep\n","Michael Jackson\n"]}]},{"cell_type":"code","source":["print(texts_test[54][:50])\n","print(labels_test[54])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wj4znsu-yBO","executionInfo":{"status":"ok","timestamp":1678627531779,"user_tz":0,"elapsed":4,"user":{"displayName":"けろりん","userId":"09772905218308909693"}},"outputId":"0cdc14fb-0f11-4fe1-c206-58f15e835fad"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Diamonds Are Invincible (Mark Ronson x Michael Jac\n","Michael Jackson\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Yukfnlf2_bYM"},"execution_count":null,"outputs":[]}]}